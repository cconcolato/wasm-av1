<!DOCTYPE html>
<html>
  <head>
    <title>AVIF Wasm decoder demo</title>
    <style>
      body { font-family: sans-serif; }
    </style>
  </head>
  <body>
    <p>Select an AVIF file</p> <input type="file" id="files" name="files[]"/>
    <br/>
    <canvas id="view" width="1280px" height="720px"></canvas>
    <script src="third_party/mp4box.js/mp4box.all.js"></script>
    <script src="avif.js"></script>
    <script src="decode-av1.js"></script>
    <script>
        let wasm_loaded = false;
        let av1_decoder = null;
        let video_running = false;
        let data_source = null;
        let rgb_image = null;
        let start_time = 0.0;
        const frame_time = 1000.0 / 24.0;   // milliseconds per frame. Demo is all 24fps video
        let frame_count = 0;
        let max_run = 0.0;
        let WIDTH = 640;
        let HEIGHT = 360;
        const measure = true;
        let high_bitdepth = false;

        Module.onRuntimeInitialized = function() {
            wasm_loaded = true;
        }

        function setup() {
            function update() {
                if (wasm_loaded) {
                    handle_tick();
                }
                requestAnimationFrame(update);
            }
            requestAnimationFrame(update);
        }
        window.onload = setup;
        if (measure) { var yuv_converts = 0, draws = 0, runs = 0, frames = 0; }
        function show_frame(af) {
            if (rgb_image != 0) {
                // Convert The 16-bit YUV to 8-bit RGB
                let buf = Module._AVX_Video_Frame_get_buffer(af);
                if (measure) { var t1 = performance.now(); }
                if (high_bitdepth) {
                    Module._AVX_YUV16_to_RGB(rgb_image, buf, WIDTH, HEIGHT, 0, 4);
                } else {
                    Module._AVX_YUV8_to_RGB(rgb_image, buf, WIDTH, HEIGHT, 0, 1);
                }
                if (measure) { var t2 = performance.now(); }
                // Paint the image onto the canvas
                drawImageToCanvas(new Uint8Array(Module.HEAPU8.buffer, rgb_image, 3 * WIDTH * HEIGHT), WIDTH, HEIGHT);
                if (measure) {
                    var t3 = performance.now();
                    frames++;
                    yuv_converts += (t2 - t1);
                    draws += (t3 - t2);
                }
            }
        }
        function handle_tick() {
            let af = 0;

            if (video_running === false) {
                return;
            }
            if (Module._AVX_Decoder_video_finished(av1_decoder)) {
                video_running = false;
                Module._DS_close(data_source);
                Module._AVX_Decoder_destroy(av1_decoder);
                if (measure) {
                    console.log(frames + " frames: " + "YUV->RGB " + yuv_converts + "ms, draw " + draws + "ms decode " + runs + "ms");
                    console.log("Max run is " + max_run + "ms");
                }
                return;
            }
            // Check if elapsed time means we should show a frame (poor mans sync)
            if ((start_time + frame_count * frame_time) > performance.now()) {
                return;
            }
            if ((af = Module._AVX_Decoder_get_frame(av1_decoder)) != 0) {
                frame_count++;
                show_frame(af);
            }
            if (measure) { var t4 = performance.now(); }
            Module._AVX_Decoder_run(av1_decoder);
            if (measure) { 
                var t5 = performance.now();
                runs += (t5 - t4);
                if (max_run < (t5 - t4)) {
                    max_run = t5 - t4;
                }
            }
        }
        var fileAsArray = undefined;
        function handleFileSelect(evt) {
            var files = evt.target.files; // FileList object

            // files is a FileList of File objects. grab the name.
            if (files[0]) {
                var f = files[0];

                if (f.name.endsWith(".avif")) {
                    parseAVIFFile(f, function(_high_bitdepth, buffer) {
                        high_bitdepth = _high_bitdepth;
                        fileAsArray = buffer;
                        start_playback();
                    });
                } else {
                    var reader = new FileReader();
                    // Closure to capture the file information.
                    reader.onload = (function(theFile) {
                        return function(e) {
                            fileAsArray = e.target.result;
                            if (fileAsArray.byteLength > 0) {
                                start_playback();
                            }
                        };
                    })(f);

                    // Read in the image file as an array buffer.
                    reader.readAsArrayBuffer(f);
                }
            }
        }
        function start_playback() {
            // Allocate a data source, get some memory from Wasm land and copy
            // the source video data into it, then kick off the decode
            av1_decoder = Module._AVX_Decoder_new();
            data_source = Module._DS_open();
            let comp_mem = Module._malloc(fileAsArray.byteLength);
            Module.HEAPU8.set(new Uint8Array(fileAsArray), comp_mem);
            Module._DS_set_blob(data_source, comp_mem, fileAsArray.byteLength);
            Module._AVX_Decoder_set_source(av1_decoder, data_source);
            // Run the decoder at the start to read the headers at least
            Module._AVX_Decoder_run(av1_decoder);
            video_running = true;
            start_time = performance.now();
            // Get the width and height of the video so we can resize our canvas appropriately
            WIDTH = Module._AVX_Decoder_get_width(av1_decoder);
            HEIGHT = Module._AVX_Decoder_get_height(av1_decoder);
            // Allocate an RGB buffer to convert the YUV frames into for display on the canvas
            rgb_image = Module._malloc(3 * WIDTH * HEIGHT);
        }
        document.getElementById('files').addEventListener('change', handleFileSelect, false);
    </script>
    <script id="vs" type="vertex-shader">
      attribute vec2 aVertex;
      attribute vec2 aTex;
      varying vec2 vTex;
      void main() {
        gl_Position = vec4(aVertex, 0.0, 1.0);
        vTex = aTex;
      }
    </script>
    <script id="fs" type="fragment-shader">
      precision mediump float;
      uniform sampler2D uTexture;
      varying vec2 vTex;
      void main() {
        gl_FragColor = texture2D(uTexture, vTex);
      }
    </script>
    <script src="draw-image.js"></script>
  </body>
</html>
